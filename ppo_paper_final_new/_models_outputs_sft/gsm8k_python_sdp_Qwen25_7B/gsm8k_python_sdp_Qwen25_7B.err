WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
W1216 00:30:08.012000 197245 torch/distributed/run.py:793] 
W1216 00:30:08.012000 197245 torch/distributed/run.py:793] *****************************************
W1216 00:30:08.012000 197245 torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1216 00:30:08.012000 197245 torch/distributed/run.py:793] *****************************************
/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/deepspeed.py:24: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/deepspeed.py:24: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/deepspeed.py:24: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/deepspeed.py:24: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
[W1216 00:30:13.031052960 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
[W1216 00:30:13.147967622 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
[W1216 00:30:13.151674619 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
[W1216 00:30:13.233952485 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[rank2]:[W1216 00:30:13.705659490 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 2]  using GPU 2 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.
[rank3]:[W1216 00:30:13.739077366 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 3]  using GPU 3 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.
[rank1]:[W1216 00:30:13.778494084 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.
wandb: Currently logged in as: yinita. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.1
wandb: Run data is saved locally in /home/aiscuser/byteReFT/wandb/run-20241216_003013-xywinxkt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gsm8k_python_sdp_Qwen25_7B
wandb: ‚≠êÔ∏è View project at https://wandb.ai/yinita/ReFT
wandb: üöÄ View run at https://wandb.ai/yinita/ReFT/runs/xywinxkt
Setting TOKENIZERS_PARALLELISM=false for forked processes.
WARNING:datasets.arrow_dataset:Setting TOKENIZERS_PARALLELISM=false for forked processes.
Map (num_proc=8):   0%|          | 0/7356 [00:00<?, ? examples/s]Map (num_proc=8):  13%|‚ñà‚ñé        | 920/7356 [00:01<00:08, 721.17 examples/s]Map (num_proc=8):  38%|‚ñà‚ñà‚ñà‚ñä      | 2760/7356 [00:01<00:01, 2311.74 examples/s]Map (num_proc=8):  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3680/7356 [00:01<00:01, 3115.02 examples/s]Map (num_proc=8):  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 4599/7356 [00:01<00:00, 3786.37 examples/s]Map (num_proc=8):  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 5518/7356 [00:01<00:00, 4530.39 examples/s]Map (num_proc=8): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7356/7356 [00:02<00:00, 5887.54 examples/s]Map (num_proc=8): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7356/7356 [00:02<00:00, 3440.70 examples/s]
Setting TOKENIZERS_PARALLELISM=false for forked processes.
WARNING:datasets.arrow_dataset:Setting TOKENIZERS_PARALLELISM=false for forked processes.
Map (num_proc=8):   0%|          | 0/1319 [00:00<?, ? examples/s]Map (num_proc=8):  13%|‚ñà‚ñé        | 165/1319 [00:00<00:04, 285.28 examples/s]Map (num_proc=8):  25%|‚ñà‚ñà‚ñå       | 330/1319 [00:00<00:01, 555.01 examples/s]Map (num_proc=8):  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 660/1319 [00:00<00:00, 1075.79 examples/s]Map (num_proc=8):  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 990/1319 [00:01<00:00, 1255.63 examples/s]Map (num_proc=8):  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1155/1319 [00:01<00:00, 1219.07 examples/s]Map (num_proc=8): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1319/1319 [00:01<00:00, 993.45 examples/s] 
[rank0]:[W1216 00:30:18.802155344 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.
Setting TOKENIZERS_PARALLELISM=false for forked processes.
WARNING:datasets.arrow_dataset:Setting TOKENIZERS_PARALLELISM=false for forked processes.
Setting TOKENIZERS_PARALLELISM=false for forked processes.
WARNING:datasets.arrow_dataset:Setting TOKENIZERS_PARALLELISM=false for forked processes.
Setting TOKENIZERS_PARALLELISM=false for forked processes.
WARNING:datasets.arrow_dataset:Setting TOKENIZERS_PARALLELISM=false for forked processes.
Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Map (num_proc=8):   0%|          | 0/7356 [00:00<?, ? examples/s]Map (num_proc=8):   0%|          | 0/7356 [00:00<?, ? examples/s]Map (num_proc=8):   0%|          | 0/7356 [00:00<?, ? examples/s]Map (num_proc=8):  13%|‚ñà‚ñé        | 920/7356 [00:01<00:08, 719.05 examples/s]Map (num_proc=8):  13%|‚ñà‚ñé        | 920/7356 [00:01<00:09, 709.06 examples/s]Map (num_proc=8):  13%|‚ñà‚ñé        | 920/7356 [00:01<00:09, 671.03 examples/s]Map (num_proc=8):  25%|‚ñà‚ñà‚ñå       | 1840/7356 [00:01<00:03, 1507.31 examples/s]Map (num_proc=8):  25%|‚ñà‚ñà‚ñå       | 1840/7356 [00:01<00:03, 1462.12 examples/s]Map (num_proc=8):  25%|‚ñà‚ñà‚ñå       | 1840/7356 [00:01<00:03, 1462.89 examples/s]Map (num_proc=8):  38%|‚ñà‚ñà‚ñà‚ñä      | 2760/7356 [00:01<00:01, 2369.28 examples/s]Map (num_proc=8):  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3680/7356 [00:01<00:01, 3164.67 examples/s]Map (num_proc=8):  38%|‚ñà‚ñà‚ñà‚ñä      | 2760/7356 [00:01<00:01, 2336.68 examples/s]Map (num_proc=8):  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3680/7356 [00:01<00:01, 3062.37 examples/s]Map (num_proc=8):  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 4599/7356 [00:01<00:00, 3902.01 examples/s]Map (num_proc=8):  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3680/7356 [00:01<00:01, 3022.41 examples/s]Map (num_proc=8):  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 5518/7356 [00:01<00:00, 4650.05 examples/s]Map (num_proc=8):  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 6437/7356 [00:01<00:00, 5575.45 examples/s]Map (num_proc=8):  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 5518/7356 [00:01<00:00, 4604.10 examples/s]Map (num_proc=8): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7356/7356 [00:02<00:00, 6373.10 examples/s]Map (num_proc=8): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7356/7356 [00:02<00:00, 3476.75 examples/s]
Map (num_proc=8): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7356/7356 [00:02<00:00, 5834.14 examples/s]Map (num_proc=8):  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 6437/7356 [00:02<00:00, 4915.50 examples/s]Map (num_proc=8): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7356/7356 [00:02<00:00, 3308.78 examples/s]
Setting TOKENIZERS_PARALLELISM=false for forked processes.
WARNING:datasets.arrow_dataset:Setting TOKENIZERS_PARALLELISM=false for forked processes.
Map (num_proc=8): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7356/7356 [00:02<00:00, 3199.64 examples/s]
Map (num_proc=8):   0%|          | 0/1319 [00:00<?, ? examples/s]Setting TOKENIZERS_PARALLELISM=false for forked processes.
WARNING:datasets.arrow_dataset:Setting TOKENIZERS_PARALLELISM=false for forked processes.
Map (num_proc=8):   0%|          | 0/1319 [00:00<?, ? examples/s]Setting TOKENIZERS_PARALLELISM=false for forked processes.
WARNING:datasets.arrow_dataset:Setting TOKENIZERS_PARALLELISM=false for forked processes.
Map (num_proc=8):   0%|          | 0/1319 [00:00<?, ? examples/s]Map (num_proc=8):  13%|‚ñà‚ñé        | 165/1319 [00:00<00:04, 251.58 examples/s]Map (num_proc=8):  25%|‚ñà‚ñà‚ñå       | 330/1319 [00:00<00:01, 495.75 examples/s]Map (num_proc=8):  13%|‚ñà‚ñé        | 165/1319 [00:00<00:04, 246.93 examples/s]Map (num_proc=8):  38%|‚ñà‚ñà‚ñà‚ñä      | 495/1319 [00:00<00:01, 716.09 examples/s]Map (num_proc=8):  25%|‚ñà‚ñà‚ñå       | 330/1319 [00:00<00:02, 480.83 examples/s]Map (num_proc=8):  38%|‚ñà‚ñà‚ñà‚ñä      | 495/1319 [00:00<00:01, 699.57 examples/s]Map (num_proc=8):  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 825/1319 [00:01<00:00, 1130.50 examples/s]Map (num_proc=8):  13%|‚ñà‚ñé        | 165/1319 [00:00<00:05, 219.38 examples/s]Map (num_proc=8):  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 825/1319 [00:01<00:00, 1161.30 examples/s]Map (num_proc=8):  25%|‚ñà‚ñà‚ñå       | 330/1319 [00:00<00:02, 444.17 examples/s]Map (num_proc=8):  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1155/1319 [00:01<00:00, 1319.45 examples/s]Map (num_proc=8):  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 660/1319 [00:00<00:00, 903.50 examples/s]Map (num_proc=8): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1319/1319 [00:01<00:00, 1379.81 examples/s]Map (num_proc=8):  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1155/1319 [00:01<00:00, 1249.72 examples/s]Map (num_proc=8): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1319/1319 [00:01<00:00, 926.27 examples/s] 
Map (num_proc=8):  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 825/1319 [00:01<00:00, 1009.44 examples/s]Map (num_proc=8): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1319/1319 [00:01<00:00, 1323.89 examples/s]Map (num_proc=8): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1319/1319 [00:01<00:00, 897.16 examples/s] 
Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Map (num_proc=8):  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1155/1319 [00:01<00:00, 1202.16 examples/s]Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Map (num_proc=8): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1319/1319 [00:01<00:00, 873.68 examples/s] 
Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards:  25%|‚ñà‚ñà‚ñå       | 1/4 [06:19<18:57, 379.24s/it]Downloading shards:  25%|‚ñà‚ñà‚ñå       | 1/4 [06:14<18:44, 374.94s/it]Downloading shards:  25%|‚ñà‚ñà‚ñå       | 1/4 [06:15<18:45, 375.19s/it]Downloading shards:  25%|‚ñà‚ñà‚ñå       | 1/4 [06:15<18:45, 375.29s/it]